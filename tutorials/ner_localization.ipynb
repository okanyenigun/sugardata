{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733e3a4",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/boltuix/conll2025-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bba3f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['split', 'tokens', 'ner_tags'],\n",
      "        num_rows: 143709\n",
      "    })\n",
      "})\n",
      "Train example:\n",
      "{'split': 'train', 'tokens': ['In', 'recent', 'years', ',', 'advanced', 'education', 'for', 'professionals', 'has', 'become', 'a', 'hot', 'topic', 'in', 'the', 'business', 'community', '.'], 'ner_tags': ['O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"boltuix/conll2025-ner\")\n",
    "\n",
    "print(f\"Dataset:\\n{ds}\\nTrain example:\\n{ds['train'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26cec429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First tokens: ['In', 'recent', 'years', ',', 'advanced', 'education', 'for', 'professionals', 'has', 'become', 'a', 'hot', 'topic', 'in', 'the', 'business', 'community', '.']\n",
      "First BIO tags: ['O', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Formatted NER example:\n",
      "{'text': 'In recent years, advanced education for professionals has become a hot topic in the business community.', 'ner_tags': [{'recent years': 'DATE'}]}\n"
     ]
    }
   ],
   "source": [
    "from sugardata.utility.ner import NERExampleFormatter\n",
    "\n",
    "WANTED_LABELS = [\"PERSON\", \"DATE\", \"ORG\", \"LOC\", \"EVENT\"]\n",
    "FULL_TO_SHORT = {\n",
    "    \"PERSON\": \"PER\",\n",
    "    \"DATE\": \"DATE\",\n",
    "    \"ORG\": \"ORG\",\n",
    "    \"LOC\": \"LOC\",\n",
    "    \"EVENT\": \"EVENT\"\n",
    "}\n",
    "\n",
    "tokens_list = [example[\"tokens\"] for example in ds[\"train\"]]\n",
    "bio_tags_list = [example[\"ner_tags\"] for example in ds[\"train\"]]\n",
    "\n",
    "print(f\"First tokens: {tokens_list[1]}\")\n",
    "print(f\"First BIO tags: {bio_tags_list[1]}\")\n",
    "\n",
    "formatter = NERExampleFormatter(wanted_labels=WANTED_LABELS, full_to_short=FULL_TO_SHORT)\n",
    "examples = formatter.build_from_bio(tokens_list, bio_tags_list)\n",
    "\n",
    "print(f\"Formatted NER example:\\n{examples[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c65aa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Results (first 5 examples):\n",
      "{'text': 'The followers looked up, and they saw that Jesus was now alone.', 'ner_tags': []}\n",
      "----\n",
      "{'text': \"As the stock market lurched into a 190 - point free fall on Oct. 13, Mr. Breeden found himself scurrying around the sixth floor of the SEC -- from his desk, where the New York Stock Exchange was on an open line, to his assistant's office, where the Commodity Futures Trading Commission was connected, to a third room, where a computer monitored market moves.\", 'ner_tags': [{'Oct. 13': 'DATE'}, {'Breeden': 'PER'}, {'SEC': 'ORG'}, {'the New York Stock Exchange': 'ORG'}, {'the Commodity Futures Trading Commission': 'ORG'}]}\n",
      "----\n",
      "{'text': 'John Markese, director of research for the American Association of Individual Investors, raises a cautionary note.', 'ner_tags': [{'John Markese': 'PER'}, {'the American Association of Individual Investors': 'ORG'}]}\n",
      "----\n",
      "{'text': 'So far, the bubbles have been few and far between.', 'ner_tags': []}\n",
      "----\n",
      "{'text': \"Josiah obeyed God's teachings -- he did exactly what God wanted.\", 'ner_tags': []}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample_count = 5_000\n",
    "\n",
    "sample_indices = random.sample(range(len(examples)), sample_count)\n",
    "\n",
    "sampled_examples = [examples[i] for i in sample_indices]\n",
    "\n",
    "print(f\"Sampled Results (first 5 examples):\")\n",
    "\n",
    "for res in sampled_examples[:5]:\n",
    "    print(res)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f05945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sugardata import localize_ner_data\n",
    "\n",
    "\n",
    "examples = sampled_examples\n",
    "language = \"Turkish\"\n",
    "model = \"gpt-4o-mini\"\n",
    "vendor = \"openai\"\n",
    "tokenizer = \"dbmdz/bert-base-turkish-cased\"\n",
    "entity_labels = {\"PER\": (1, 2), \"ORG\": (3, 4), \"LOC\": (5, 6), \"DATE\": (7, 8), \"EVENT\": (9, 10)}\n",
    "batch_size = 32\n",
    "verbose = True\n",
    "\n",
    "\n",
    "results_example = localize_ner_data(\n",
    "    examples=examples[:2],\n",
    "    language=language,\n",
    "    model=model,\n",
    "    vendor=vendor,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=batch_size,\n",
    "    entity_labels=entity_labels,\n",
    "    export_type=\"default\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7d37b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization Results (first 2 examples) compared to examples:\n",
      "Example 1:\n",
      "Original: {'text': 'The followers looked up, and they saw that Jesus was now alone.', 'ner_tags': []}\n",
      "Localized: {'index': 0, 'localized_text': \"Takipçiler yukarı baktılar ve İsa'nın artık yalnız olduğunu gördüler.\", 'localized_word_mappings': {}, 'tokens': ['Takip', '##çiler', 'yukarı', 'baktı', '##lar', 've', 'İsa', \"'\", 'nın', 'artık', 'yalnız', 'olduğunu', 'gördü', '##ler', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'ner_tag_labels': {'PER': (1, 2), 'ORG': (3, 4), 'LOC': (5, 6), 'DATE': (7, 8), 'EVENT': (9, 10)}}\n",
      "----\n",
      "Example 2:\n",
      "Original: {'text': \"As the stock market lurched into a 190 - point free fall on Oct. 13, Mr. Breeden found himself scurrying around the sixth floor of the SEC -- from his desk, where the New York Stock Exchange was on an open line, to his assistant's office, where the Commodity Futures Trading Commission was connected, to a third room, where a computer monitored market moves.\", 'ner_tags': [{'Oct. 13': 'DATE'}, {'Breeden': 'PER'}, {'SEC': 'ORG'}, {'the New York Stock Exchange': 'ORG'}, {'the Commodity Futures Trading Commission': 'ORG'}]}\n",
      "Localized: {'index': 1, 'localized_text': \"Borsa 13 Ekim'de 190 puanlık bir düşüşe geçtiğinde, Bay İnce SEC'nin altıncı katında hızlıca hareket ederken kendini buldu; New York Borsa'sında açık bir hatla gününün başladığı masasından, Emtia Vadeli İşlemleri Komisyonu ile bağlantılı asistanının ofisine, piyasa hareketlerini izleyen bir bilgisayarın bulunduğu üçüncü bir odaya kadar koştu.\", 'localized_word_mappings': {'Oct. 13': '13 Ekim', 'Breeden': 'İnce', 'SEC': 'SPK', 'the New York Stock Exchange': \"New York Borsa'sı\", 'the Commodity Futures Trading Commission': 'Emtia Vadeli İşlemleri Komisyonu', '13 Ekim': 'Oct. 13', 'İnce': 'Breeden', 'SPK': 'SEC', \"New York Borsa'sı\": 'the New York Stock Exchange', 'Emtia Vadeli İşlemleri Komisyonu': 'the Commodity Futures Trading Commission'}, 'tokens': ['Borsa', '13', 'Ekim', \"'\", 'de', '190', 'puanlık', 'bir', 'düşüş', '##e', 'geçtiği', '##nde', ',', 'Bay', 'İnce', 'SE', '##C', \"'\", 'nin', 'altıncı', 'katında', 'hızlıca', 'hareket', 'ederken', 'kendini', 'buldu', ';', 'New', 'York', 'Borsa', \"'\", 'sı', '##nda', 'açık', 'bir', 'hat', '##la', 'gününü', '##n', 'başladığı', 'masası', '##ndan', ',', 'Em', '##tia', 'Vadeli', 'İşlemleri', 'Komisyonu', 'ile', 'bağlantılı', 'asistan', '##ının', 'ofisi', '##ne', ',', 'piyasa', 'hareketlerini', 'izleyen', 'bir', 'bilgisayarın', 'bulunduğu', 'üçüncü', 'bir', 'odaya', 'kadar', 'koş', '##tu', '.'], 'ner_tags': [0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'ner_tag_labels': {'PER': (1, 2), 'ORG': (3, 4), 'LOC': (5, 6), 'DATE': (7, 8), 'EVENT': (9, 10)}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(f\"Localization Results (first 2 examples) compared to examples:\")\n",
    "for i in range(2):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Original:\", examples[i])\n",
    "    print(\"Localized:\", results_example[i])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ce474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sugardata import localize_ner_data_async\n",
    "\n",
    "local_example_async = await localize_ner_data_async(\n",
    "    examples=examples[:2],\n",
    "    language=language,\n",
    "    model=model,\n",
    "    vendor=vendor,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=batch_size,\n",
    "    entity_labels=entity_labels,\n",
    "    export_type=\"default\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9e109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization Results (first 2 examples) compared to examples:\n",
      "Example 1:\n",
      "Original: {'text': 'The followers looked up, and they saw that Jesus was now alone.', 'ner_tags': []}\n",
      "Localized: {'index': 0, 'localized_text': \"Takipçiler yukarı baktılar ve İsa'nın şimdi yalnız olduğunu gördüler.\", 'localized_word_mappings': {}, 'tokens': ['Takip', '##çiler', 'yukarı', 'baktı', '##lar', 've', 'İsa', \"'\", 'nın', 'şimdi', 'yalnız', 'olduğunu', 'gördü', '##ler', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'ner_tag_labels': {'PER': (1, 2), 'ORG': (3, 4), 'LOC': (5, 6), 'DATE': (7, 8), 'EVENT': (9, 10)}}\n",
      "----\n",
      "Example 2:\n",
      "Original: {'text': \"As the stock market lurched into a 190 - point free fall on Oct. 13, Mr. Breeden found himself scurrying around the sixth floor of the SEC -- from his desk, where the New York Stock Exchange was on an open line, to his assistant's office, where the Commodity Futures Trading Commission was connected, to a third room, where a computer monitored market moves.\", 'ner_tags': [{'Oct. 13': 'DATE'}, {'Breeden': 'PER'}, {'SEC': 'ORG'}, {'the New York Stock Exchange': 'ORG'}, {'the Commodity Futures Trading Commission': 'ORG'}]}\n",
      "Localized: {'index': 1, 'localized_text': \"Borsa, 13 Ekim'de 190 puanlık bir düşüş yaşarken, Bay Uğur Koç, SEC'nin altıncı katında aceleyle dolaşırken buldu kendini. New York Borsa'sı ile açık hat üzerinden konuştuğu masasından, Emtia Vadeli İşlemler Komisyonu'nun bağlı olduğu asistanının ofisine, piyasa hareketlerini izleyen bir bilgisayarın bulunduğu üçüncü odaya geçti.\", 'localized_word_mappings': {'Oct. 13': '13 Ekim', 'Breeden': 'Uğur Koç', 'SEC': 'Sermaye Piyasası Kurulu', 'the New York Stock Exchange': \"New York Borsa'sı\", 'the Commodity Futures Trading Commission': 'Emtia Vadeli İşlemler Komisyonu', '13 Ekim': 'Oct. 13', 'Uğur Koç': 'Breeden', 'Sermaye Piyasası Kurulu': 'SEC', \"New York Borsa'sı\": 'the New York Stock Exchange', 'Emtia Vadeli İşlemler Komisyonu': 'the Commodity Futures Trading Commission'}, 'tokens': ['Borsa', ',', '13', 'Ekim', \"'\", 'de', '190', 'puanlık', 'bir', 'düşüş', 'yaşarken', ',', 'Bay', 'Uğur', 'Koç', ',', 'SE', '##C', \"'\", 'nin', 'altıncı', 'katında', 'acele', '##yle', 'dolaş', '##ırken', 'buldu', 'kendini', '.', 'New', 'York', 'Borsa', \"'\", 'sı', 'ile', 'açık', 'hat', 'üzerinden', 'konuştuğ', '##u', 'masası', '##ndan', ',', 'Em', '##tia', 'Vadeli', 'İşlem', '##ler', 'Komisyonu', \"'\", 'nun', 'bağlı', 'olduğu', 'asistan', '##ının', 'ofisi', '##ne', ',', 'piyasa', 'hareketlerini', 'izleyen', 'bir', 'bilgisayarın', 'bulunduğu', 'üçüncü', 'odaya', 'geçti', '.'], 'ner_tags': [0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'ner_tag_labels': {'PER': (1, 2), 'ORG': (3, 4), 'LOC': (5, 6), 'DATE': (7, 8), 'EVENT': (9, 10)}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(f\"Localization Results (first 2 examples) compared to examples:\")\n",
    "for i in range(2):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Original:\", examples[i])\n",
    "    print(\"Localized:\", local_example_async[i])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9ff6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt-4o-mini] Starting text generation: 40 batches\n",
      "[gemma3:12b] Starting text generation: 40 batches\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Starting text generation: 40 batches\n",
      "[models/gemini-2.0-flash-lite] Starting text generation: 40 batches\n",
      "Error in batch item 19: OutputParserException: Invalid json output: Here is the output:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"index\": 19,\n",
      "  \"localized_text\": \"\"Sağlık kulübü yetişkinler için bir oyun alanı, işte bu!\" diyor Bay Özdemir, bir çiçekçi.\",\n",
      "  \"localized_word_mappin...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 1/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 1/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 2/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 2/40\n",
      "Error in batch item 7: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 3/40\n",
      "[gpt-4o-mini] Generated batch 1/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 3/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 4/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion {\"Lafite-Rothschild\": \"Lafite-Rothschild\", \"Latour\": \"Latour\", \"Haut-Brion\": \"Haut-Brion\", \"Petrus\": \"Petrus\", \"Romanee-Conti\": \"Romanee-Conti\", \"La Tache\"...\n",
      "Total errors: 2\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 4/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 5/40\n",
      "[gpt-4o-mini] Generated batch 2/40\n",
      "Error in batch item 19: OutputParserException: Invalid json output: Here is the output:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"index\": 147,\n",
      "  \"localized_text\": \"Aslında, çok çelişkili hissediyorum,\" itiraf ediyor.\n",
      "  \"localized_word_mappings\": {}\n",
      "}\n",
      "```\n",
      "\n",
      "Explanation:\n",
      "\n",
      "* The ori...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 5/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 6/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 6/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 7/40\n",
      "Error in batch item 2: OutputParserException: Failed to parse NERLocalText from completion {\"Donnybrook\": \"Kavga\"}. Got: 3 validation errors for NERLocalText\n",
      "index\n",
      "  Field required [type=missing, input_value={'Donnybrook': 'Kavga'}, input_type=di...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 7/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 8/40\n",
      "[gpt-4o-mini] Generated batch 3/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 9/40\n",
      "Error in batch item 18: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 8/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 10/40\n",
      "Error in batch item 24: OutputParserException: Failed to parse NERLocalText from completion {\"the previous year\": \"ge\\u00e7en y\\u0131l\"}. Got: 3 validation errors for NERLocalText\n",
      "index\n",
      "  Field required [type=missing, input_value={'the previous ye...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 9/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 11/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 10/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 12/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 11/40\n",
      "Error in batch item 6: OutputParserException: Failed to parse NERLocalText from completion null. Got: 1 validation error for NERLocalText\n",
      "  Input should be a valid dictionary or instance of NERLocalText [type=model_type, input_value=None, input_t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 13/40\n",
      "[gpt-4o-mini] Generated batch 4/40\n",
      "Error in batch item 0: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 4\n",
      "[gemma3:12b] Generated batch 1/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 14/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 12/40\n",
      "Error in batch item 26: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 15/40\n",
      "[gpt-4o-mini] Generated batch 5/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 16/40\n",
      "Error in batch item 0: OutputParserException: Failed to parse NERLocalText from completion \"`` We like to follow up and make sure operators are achieving our standards of company service,''says Ms. Dale, who supervises 350 operators.\". Got: 1 val...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 13/40\n",
      "Error in batch item 0: OutputParserException: Failed to parse NERLocalText from completion null. Got: 1 validation error for NERLocalText\n",
      "  Input should be a valid dictionary or instance of NERLocalText [type=model_type, input_value=None, input_t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 17/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 14/40\n",
      "[gpt-4o-mini] Generated batch 6/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 18/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 15/40\n",
      "Error in batch item 22: OutputParserException: Failed to parse NERLocalText from completion null. Got: 1 validation error for NERLocalText\n",
      "  Input should be a valid dictionary or instance of NERLocalText [type=model_type, input_value=None, input_t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 19/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 20/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 16/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 21/40\n",
      "[gpt-4o-mini] Generated batch 7/40\n",
      "Error in batch item 8: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 5\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 17/40\n",
      "[gpt-4o-mini] Generated batch 8/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 10\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 18/40\n",
      "[gpt-4o-mini] Generated batch 9/40\n",
      "Error in batch item 20: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 2/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 9\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 19/40\n",
      "[gpt-4o-mini] Generated batch 10/40\n",
      "Error in batch item 23: OutputParserException: Failed to parse NERLocalText from completion {\"index\": 695, \"localized_text\": \"%\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131\\u0131...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 22/40\n",
      "[gpt-4o-mini] Generated batch 11/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 23/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 24/40\n",
      "[gpt-4o-mini] Generated batch 12/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 25/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 26/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 27/40\n",
      "Error in batch item 13: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 28/40\n",
      "[gpt-4o-mini] Generated batch 13/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 11\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 20/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 29/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 3\n",
      "[gemma3:12b] Generated batch 3/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 21/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 30/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 31/40\n",
      "Error in batch item 7: OutputParserException: Invalid json output: Here is the output:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"index\": 679,\n",
      "  \"localized_text\": \"Nikodemus dedi ki, `` Nasıl oluyor da yaşlı bir adam tekrar doğabilir?\"\n",
      "  \"localized_word_mappings\": {}\n",
      "}\n",
      "```\n",
      "\n",
      "Note...\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 22/40\n",
      "[gpt-4o-mini] Generated batch 14/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 32/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 23/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 33/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 24/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 34/40\n",
      "[gpt-4o-mini] Generated batch 15/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion null. Got: 1 validation error for NERLocalText\n",
      "  Input should be a valid dictionary or instance of NERLocalText [type=model_type, input_value=None, input_t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 35/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion \"`` We don't anticipate any problems in raising the funding for the bid,''said Allan Campbell, the head of mergers and acquisitions at Hoare Govett, in an ...\n",
      "Total errors: 2\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 25/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 36/40\n",
      "Error in batch item 2: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[models/gemini-2.0-flash-lite] Generated batch 37/40\n",
      "Error in batch item 14: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 4\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 26/40\n",
      "[gpt-4o-mini] Generated batch 16/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 38/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 39/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 6\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 27/40\n",
      "[models/gemini-2.0-flash-lite] Generated batch 40/40\n",
      "[models/gemini-2.0-flash-lite] Text generation complete\n",
      "[models/gemini-2.0-flash-lite] Starting entity labeling: 1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 50/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 100/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 150/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 200/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 250/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 300/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 350/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 400/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 450/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 500/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 550/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 600/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 650/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 700/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 750/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 800/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 850/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 900/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 950/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 1000/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 1050/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 1100/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 1150/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 1200/1242 records\n",
      "[models/gemini-2.0-flash-lite] Labeled 1242/1242 records\n",
      "[models/gemini-2.0-flash-lite] Entity labeling complete\n",
      "[gemma3:12b] Generated batch 4/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 10\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 28/40\n",
      "[gpt-4o-mini] Generated batch 17/40\n",
      "Error in batch item 3: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 14\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 29/40\n",
      "[gpt-4o-mini] Generated batch 18/40\n",
      "[gpt-4o-mini] Generated batch 19/40\n",
      "Error in batch item 0: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 6\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 30/40\n",
      "[gpt-4o-mini] Generated batch 20/40\n",
      "Error in batch item 6: OutputParserException: Failed to parse NERLocalText from completion {\"index\": 966, \"localized_text\": \"ama b\\u00fct\\u00fcn y\\u0131l s\\u00fcrd\\u00fc,\"}. Got: 1 validation error for NERLocalText\n",
      "localized_word_mappings\n",
      "  Field...\n",
      "Total errors: 2\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 31/40\n",
      "[gpt-4o-mini] Generated batch 21/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 8\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 32/40\n",
      "[gpt-4o-mini] Generated batch 22/40\n",
      "Error in batch item 13: OutputParserException: Failed to parse NERLocalText from completion {\"index\": 141, \"localized_text\": \"\\u0130sve\\u00e7li otomotiv ve havac\\u0131l\\u0131k devi Volvo - Anadolu Otomotiv, \\u0130svi\\u00e7reli b\\u00f6lgesel havayo...\n",
      "Total errors: 3\n",
      "[gemma3:12b] Generated batch 5/40\n",
      "Error in batch item 2: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 8\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 33/40\n",
      "Error in batch item 9: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 5\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 34/40\n",
      "[gpt-4o-mini] Generated batch 23/40\n",
      "Error in batch item 8: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 9\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 35/40\n",
      "[gpt-4o-mini] Generated batch 24/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 13\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 36/40\n",
      "[gpt-4o-mini] Generated batch 25/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 11\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 37/40\n",
      "Error in batch item 8: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 9\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 38/40\n",
      "[gpt-4o-mini] Generated batch 26/40\n",
      "Error in batch item 6: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 6/40\n",
      "Error in batch item 5: RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-scout-17b-16e-instruct` in organization `org_01j4hfjqbdf57rht3xr7a0dtvn` service tier `on_demand` on tokens pe...\n",
      "Total errors: 12\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 39/40\n",
      "[gpt-4o-mini] Generated batch 27/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Generated batch 40/40\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Text generation complete\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Starting entity labeling: 1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 50/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 100/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 150/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 200/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 250/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 300/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 350/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 400/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 450/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 500/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 550/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 600/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 650/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 700/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 750/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 800/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 850/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 900/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 950/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 1000/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 1050/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Labeled 1084/1084 records\n",
      "[meta-llama/llama-4-scout-17b-16e-instruct] Entity labeling complete\n",
      "[gpt-4o-mini] Generated batch 28/40\n",
      "Error in batch item 15: OutputParserException: Failed to parse NERLocalText from completion {\"index\": 911, \"localized_text\": \"\\u0130sa on iki ya\\u015f\\u0131ndayken, her zamanki gibi festivale gittiler.\", \"localized_word_mappings\": []}. Got: 1 vali...\n",
      "[gpt-4o-mini] Generated batch 29/40\n",
      "[gpt-4o-mini] Generated batch 30/40\n",
      "[gpt-4o-mini] Generated batch 31/40\n",
      "Error in batch item 3: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 3\n",
      "[gemma3:12b] Generated batch 7/40\n",
      "[gpt-4o-mini] Generated batch 32/40\n",
      "[gpt-4o-mini] Generated batch 33/40\n",
      "[gpt-4o-mini] Generated batch 34/40\n",
      "[gpt-4o-mini] Generated batch 35/40\n",
      "Error in batch item 16: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 8/40\n",
      "[gpt-4o-mini] Generated batch 36/40\n",
      "[gpt-4o-mini] Generated batch 37/40\n",
      "[gpt-4o-mini] Generated batch 38/40\n",
      "[gpt-4o-mini] Generated batch 39/40\n",
      "[gpt-4o-mini] Generated batch 40/40\n",
      "[gpt-4o-mini] Text generation complete\n",
      "[gpt-4o-mini] Starting entity labeling: 1249 records\n",
      "[gpt-4o-mini] Labeled 50/1249 records\n",
      "[gpt-4o-mini] Labeled 100/1249 records\n",
      "[gpt-4o-mini] Labeled 150/1249 records\n",
      "[gpt-4o-mini] Labeled 200/1249 records\n",
      "[gpt-4o-mini] Labeled 250/1249 records\n",
      "[gpt-4o-mini] Labeled 300/1249 records\n",
      "[gpt-4o-mini] Labeled 350/1249 records\n",
      "[gpt-4o-mini] Labeled 400/1249 records\n",
      "[gpt-4o-mini] Labeled 450/1249 records\n",
      "[gpt-4o-mini] Labeled 500/1249 records\n",
      "[gpt-4o-mini] Labeled 550/1249 records\n",
      "[gpt-4o-mini] Labeled 600/1249 records\n",
      "[gpt-4o-mini] Labeled 650/1249 records\n",
      "[gpt-4o-mini] Labeled 700/1249 records\n",
      "[gpt-4o-mini] Labeled 750/1249 records\n",
      "[gpt-4o-mini] Labeled 800/1249 records\n",
      "[gpt-4o-mini] Labeled 850/1249 records\n",
      "[gpt-4o-mini] Labeled 900/1249 records\n",
      "[gpt-4o-mini] Labeled 950/1249 records\n",
      "[gpt-4o-mini] Labeled 1000/1249 records\n",
      "[gpt-4o-mini] Labeled 1050/1249 records\n",
      "[gpt-4o-mini] Labeled 1100/1249 records\n",
      "[gpt-4o-mini] Labeled 1150/1249 records\n",
      "[gpt-4o-mini] Labeled 1200/1249 records\n",
      "[gpt-4o-mini] Labeled 1249/1249 records\n",
      "[gpt-4o-mini] Entity labeling complete\n",
      "Error in batch item 12: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 5\n",
      "[gemma3:12b] Generated batch 9/40\n",
      "Error in batch item 0: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 10/40\n",
      "Error in batch item 3: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 11/40\n",
      "Error in batch item 16: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 12/40\n",
      "Error in batch item 5: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 13/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 14/40\n",
      "Error in batch item 23: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 15/40\n",
      "Error in batch item 0: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 4\n",
      "[gemma3:12b] Generated batch 16/40\n",
      "Error in batch item 4: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 17/40\n",
      "Error in batch item 23: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 18/40\n",
      "Error in batch item 29: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 19/40\n",
      "Error in batch item 15: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 20/40\n",
      "Error in batch item 2: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 21/40\n",
      "Error in batch item 4: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 22/40\n",
      "Error in batch item 11: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 23/40\n",
      "[gemma3:12b] Generated batch 24/40\n",
      "[gemma3:12b] Generated batch 25/40\n",
      "Error in batch item 16: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 3\n",
      "[gemma3:12b] Generated batch 26/40\n",
      "Error in batch item 7: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 27/40\n",
      "Error in batch item 21: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 28/40\n",
      "Error in batch item 22: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 29/40\n",
      "Error in batch item 6: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 3\n",
      "[gemma3:12b] Generated batch 30/40\n",
      "Error in batch item 21: OutputParserException: Invalid json output: ```json\n",
      "{\n",
      "  \"index\": 981,\n",
      "  \"localized_text\": \"Dün gibi, on yılı bitiremeden internet üzerinden BBC HD alacağımızı söylüyordum ve bana ne kadar yanlış söylediğimi ve süper hızlı g...\n",
      "[gemma3:12b] Generated batch 31/40\n",
      "[gemma3:12b] Generated batch 32/40\n",
      "Error in batch item 1: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 3\n",
      "[gemma3:12b] Generated batch 33/40\n",
      "Error in batch item 5: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 4\n",
      "[gemma3:12b] Generated batch 34/40\n",
      "Error in batch item 1: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 35/40\n",
      "Error in batch item 9: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 2\n",
      "[gemma3:12b] Generated batch 36/40\n",
      "Error in batch item 0: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "Total errors: 7\n",
      "[gemma3:12b] Generated batch 37/40\n",
      "Error in batch item 8: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 38/40\n",
      "Error in batch item 5: OutputParserException: Failed to parse NERLocalText from completion {\"properties\": {\"index\": {\"description\": \"Index of the given request\", \"title\": \"Index\", \"type\": \"integer\"}, \"localized_text\": {\"description\": \"Localized t...\n",
      "[gemma3:12b] Generated batch 39/40\n",
      "[gemma3:12b] Generated batch 40/40\n",
      "[gemma3:12b] Text generation complete\n",
      "[gemma3:12b] Starting entity labeling: 1174 records\n",
      "[gemma3:12b] Labeled 50/1174 records\n",
      "[gemma3:12b] Labeled 100/1174 records\n",
      "[gemma3:12b] Labeled 150/1174 records\n",
      "[gemma3:12b] Labeled 200/1174 records\n",
      "[gemma3:12b] Labeled 250/1174 records\n",
      "[gemma3:12b] Labeled 300/1174 records\n",
      "[gemma3:12b] Labeled 350/1174 records\n",
      "[gemma3:12b] Labeled 400/1174 records\n",
      "[gemma3:12b] Labeled 450/1174 records\n",
      "[gemma3:12b] Labeled 500/1174 records\n",
      "[gemma3:12b] Labeled 550/1174 records\n",
      "[gemma3:12b] Labeled 600/1174 records\n",
      "[gemma3:12b] Labeled 650/1174 records\n",
      "[gemma3:12b] Labeled 700/1174 records\n",
      "[gemma3:12b] Labeled 750/1174 records\n",
      "[gemma3:12b] Labeled 800/1174 records\n",
      "[gemma3:12b] Labeled 850/1174 records\n",
      "[gemma3:12b] Labeled 900/1174 records\n",
      "[gemma3:12b] Labeled 950/1174 records\n",
      "[gemma3:12b] Labeled 1000/1174 records\n",
      "[gemma3:12b] Labeled 1050/1174 records\n",
      "[gemma3:12b] Labeled 1100/1174 records\n",
      "[gemma3:12b] Labeled 1150/1174 records\n",
      "[gemma3:12b] Labeled 1174/1174 records\n",
      "[gemma3:12b] Entity labeling complete\n"
     ]
    }
   ],
   "source": [
    "from sugardata import localize_ner_data_multi_vendor_async\n",
    "\n",
    "examples = sampled_examples\n",
    "batch_size = 32\n",
    "verbose = True\n",
    "\n",
    "vendors = {\n",
    "    \"openai\": \"gpt-4o-mini\",\n",
    "    \"gemini\": \"gemini-2.0-flash-lite\",\n",
    "    \"groq\": \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    \"ollama\": \"gemma3:12b\",\n",
    "}\n",
    "\n",
    "results = await localize_ner_data_multi_vendor_async(\n",
    "    examples=sampled_examples,\n",
    "    language=language,\n",
    "    tokenizer=tokenizer,\n",
    "    entity_labels=entity_labels,\n",
    "    batch_size=batch_size,\n",
    "    vendors=vendors,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c02fb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total localized examples: 4749\n"
     ]
    }
   ],
   "source": [
    "local_data = []\n",
    "for vendor, vendor_results in results.items():\n",
    "    local_data.extend(vendor_results)\n",
    "\n",
    "print(f\"Total localized examples: {len(local_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e47287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "NER_LABELS: Dict[str, Tuple[int,int]] = {\n",
    "    'PER': (1, 2),\n",
    "    'ORG':    (3, 4),\n",
    "    'LOC':    (5, 6),\n",
    "    'DATE':   (7, 8),\n",
    "    'EVENT':  (9,10),\n",
    "}\n",
    "\n",
    "id2label = {0: \"O\"}\n",
    "for ent, (b_id, i_id) in NER_LABELS.items():\n",
    "    id2label[b_id] = f\"B-{ent}\"\n",
    "    id2label[i_id] = f\"I-{ent}\"\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_labels = max(id2label.keys()) + 1\n",
    "\n",
    "\n",
    "assert all(isinstance(x[\"tokens\"], list) and isinstance(x[\"ner_tags\"], list) for x in local_data)\n",
    "assert all(len(x[\"tokens\"]) == len(x[\"ner_tags\"]) for x in local_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c497a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['index', 'localized_text', 'localized_word_mappings', 'tokens', 'ner_tags', 'ner_tag_labels'],\n",
      "        num_rows: 3799\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['index', 'localized_text', 'localized_word_mappings', 'tokens', 'ner_tags', 'ner_tag_labels'],\n",
      "        num_rows: 475\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['index', 'localized_text', 'localized_word_mappings', 'tokens', 'ner_tags', 'ner_tag_labels'],\n",
      "        num_rows: 475\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train / validation / test split (80/10/10)\n",
    "random.seed(42)\n",
    "idx = list(range(len(local_data)))\n",
    "train_idx, tmp_idx = train_test_split(idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "valid_idx, test_idx = train_test_split(tmp_idx, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_data = [local_data[i] for i in train_idx]\n",
    "valid_data = [local_data[i] for i in valid_idx]\n",
    "test_data  = [local_data[i] for i in test_idx]\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_data),\n",
    "    \"validation\": Dataset.from_list(valid_data),\n",
    "    \"test\": Dataset.from_list(test_data),\n",
    "})\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ff9b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf874949fd20449da1ee8f07f77e5e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf1d82d7402466a974f8db127854315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b187ec773643fba6d2739ec90adba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['index', 'localized_text', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3799\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['index', 'localized_text', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 475\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['index', 'localized_text', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 475\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "CLS_ID = tokenizer.cls_token_id\n",
    "SEP_ID = tokenizer.sep_token_id\n",
    "PAD_ID = tokenizer.pad_token_id\n",
    "\n",
    "def encode_example(example, max_length=256):\n",
    "    # Convert your piecewise tokens → ids (unknown pieces become [UNK])\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(example[\"tokens\"])\n",
    "    attention_mask = [1]*len(input_ids)\n",
    "\n",
    "    # Add special tokens [CLS] ... [SEP]\n",
    "    input_ids = [CLS_ID] + input_ids + [SEP_ID]\n",
    "    attention_mask = [1] + attention_mask + [1]\n",
    "\n",
    "    # Shift labels: add -100 for [CLS] and [SEP] so they are ignored by the loss\n",
    "    labels = [-100] + example[\"ner_tags\"] + [-100]\n",
    "\n",
    "    # Truncate if needed (keep room already considered)\n",
    "    if len(input_ids) > max_length:\n",
    "        input_ids   = input_ids[:max_length]\n",
    "        attention_mask = attention_mask[:max_length]\n",
    "        labels = labels[:max_length]\n",
    "\n",
    "    # No padding here; DataCollator will pad dynamically per batch\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"localized_text\": example.get(\"localized_text\", \"\"),\n",
    "        \"index\": example.get(\"index\", -1),\n",
    "    }\n",
    "\n",
    "encoded_ds = ds.map(encode_example, remove_columns=ds[\"train\"].column_names)\n",
    "\n",
    "print(f\"Encoded dataset:\\n{encoded_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95b8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoConfig, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer, padding=True, max_length=256)\n",
    "\n",
    "# Build a function to convert label ids back to strings (excluding -100 and specials)\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "    batch_preds = []\n",
    "    batch_refs = []\n",
    "\n",
    "    for pred, lab in zip(preds, label_ids):\n",
    "        true_preds = []\n",
    "        true_labels = []\n",
    "        for p, l in zip(pred, lab):\n",
    "            if l == -100:\n",
    "                continue\n",
    "            true_preds.append(id2label[p])\n",
    "            true_labels.append(id2label[l])\n",
    "        batch_preds.append(true_preds)\n",
    "        batch_refs.append(true_labels)\n",
    "    return batch_preds, batch_refs\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds_list, refs_list = align_predictions(predictions, labels)\n",
    "    results = seqeval.compute(predictions=preds_list, references=refs_list)\n",
    "    # Friendly flatten of main scores\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\":    results[\"overall_recall\"],\n",
    "        \"f1\":        results[\"overall_f1\"],\n",
    "        \"accuracy\":  results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bert-tr-ner\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=1,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",   # set \"wandb\" etc. if you want\n",
    "    seed=42,\n",
    "    dataloader_num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a756a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6075/1448628327.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='714' max='714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [714/714 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.109692</td>\n",
       "      <td>0.594340</td>\n",
       "      <td>0.653979</td>\n",
       "      <td>0.622735</td>\n",
       "      <td>0.962301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.110344</td>\n",
       "      <td>0.587879</td>\n",
       "      <td>0.671280</td>\n",
       "      <td>0.626817</td>\n",
       "      <td>0.964121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.122452</td>\n",
       "      <td>0.619195</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.653595</td>\n",
       "      <td>0.964335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=714, training_loss=0.12100787815593537, metrics={'train_runtime': 16.0634, 'train_samples_per_second': 709.501, 'train_steps_per_second': 44.449, 'total_flos': 310492761022392.0, 'train_loss': 0.12100787815593537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_ds[\"train\"],\n",
    "    eval_dataset=encoded_ds[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,     # keeps special tokens, etc.\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddbc22f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09789253771305084, 'eval_precision': 0.7044673539518901, 'eval_recall': 0.7735849056603774, 'eval_f1': 0.737410071942446, 'eval_accuracy': 0.973923393204934, 'eval_runtime': 0.2595, 'eval_samples_per_second': 1830.683, 'eval_steps_per_second': 115.622, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(encoded_ds[\"test\"])\n",
    "print(test_metrics)  # precision / recall / f1 / accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ad65e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/yeniguno/projects/sugardata/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': {'precision': np.float64(0.5934065934065934), 'recall': np.float64(0.6923076923076923), 'f1': np.float64(0.6390532544378699), 'number': np.int64(78)}, 'EVENT': {'precision': np.float64(0.4), 'recall': np.float64(0.5), 'f1': np.float64(0.4444444444444445), 'number': np.int64(4)}, 'LOC': {'precision': np.float64(0.3), 'recall': np.float64(0.375), 'f1': np.float64(0.33333333333333326), 'number': np.int64(8)}, 'ORG': {'precision': np.float64(0.7272727272727273), 'recall': np.float64(0.8205128205128205), 'f1': np.float64(0.7710843373493976), 'number': np.int64(78)}, 'PER': {'precision': np.float64(0.845360824742268), 'recall': np.float64(0.845360824742268), 'f1': np.float64(0.845360824742268), 'number': np.int64(97)}, 'overall_precision': np.float64(0.7044673539518901), 'overall_recall': np.float64(0.7735849056603774), 'overall_f1': np.float64(0.737410071942446), 'overall_accuracy': 0.973923393204934}\n"
     ]
    }
   ],
   "source": [
    "# Get raw predictions for per-class report\n",
    "predictions = trainer.predict(encoded_ds[\"test\"])\n",
    "preds_list, refs_list = align_predictions(predictions.predictions, predictions.label_ids)\n",
    "report = evaluate.load(\"seqeval\").compute(predictions=preds_list, references=refs_list)\n",
    "print(report)  # includes per-entity scores like B-PERSON/I-PERSON aggregated as PER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8160814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('outputs/bert-tr-ner/final/tokenizer_config.json',\n",
       " 'outputs/bert-tr-ner/final/special_tokens_map.json',\n",
       " 'outputs/bert-tr-ner/final/vocab.txt',\n",
       " 'outputs/bert-tr-ner/final/added_tokens.json',\n",
       " 'outputs/bert-tr-ner/final/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"outputs/bert-tr-ner/final\")\n",
    "tokenizer.save_pretrained(\"outputs/bert-tr-ner/final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30a66b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9808618),\n",
       "  'word': 'Ahmet Öztürk',\n",
       "  'start': 49,\n",
       "  'end': 61}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipe = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=\"outputs/bert-tr-ner/final\",\n",
    "    tokenizer=\"outputs/bert-tr-ner/final\",\n",
    "    aggregation_strategy=\"simple\"   # merges sub-tokens into whole entities\n",
    ")\n",
    "\n",
    "text = \"Savcı, kabul karşılığında davayı sonlandırmış ve Ahmet Öztürk'ü suçlama planlarından vazgeçmiştir.\"\n",
    "preds = ner_pipe(text)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca19d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
